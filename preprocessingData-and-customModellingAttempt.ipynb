{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment, install ini dulu\n",
    "# ini ku uncomment soalnya udh nginstall,\n",
    "# takut makan kuota wakakaka\n",
    "\n",
    "# %pip install tensorflow\n",
    "# %pip install tensorflow_hub\n",
    "# %pip install scikit-learn\n",
    "# %pip install tensorflow vggish-slim\n",
    "# %pip install librosa\n",
    "# %pip install resampy librosa tensorflow numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mel_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvggish\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mel_features\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvggish\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vggish_input, vggish_params, vggish_postprocess, mel_features\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# import vggish_input\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# import vggish_params\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# import vggish_postprocess\u001b[39;00m\n",
      "File \u001b[1;32md:\\StuPen\\Capstone\\vggish\\vggish_input.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mresampy\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmel_features\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvggish_params\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mel_features'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from vggish import mel_features\n",
    "from vggish import vggish_input, vggish_params, vggish_postprocess, mel_features\n",
    "# import vggish_input\n",
    "# import vggish_params\n",
    "# import vggish_postprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load VGGish model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vggish_model():\n",
    "    vggish_model = hub.load('https://tfhub.dev/google/vggish/1')\n",
    "    return vggish_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio_vggish(audio_path):\n",
    "    \n",
    "    audio_data, sample_rate = librosa.load(audio_path, sr=vggish_params.SAMPLE_RATE)\n",
    "\n",
    "    examples_batch = vggish_input.waveform_to_examples(audio_data, sample_rate)\n",
    "    \n",
    "    return examples_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load audio files and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(directory):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            label_file = os.path.join(folder_path, 'new_label.txt')\n",
    "            with open(label_file, 'r') as f:\n",
    "                sds_score = float(f.read().strip())\n",
    "                if sds_score < 40:\n",
    "                    label = 'low'\n",
    "                elif 41 >= sds_score <= 60:\n",
    "                    label = 'medium'\n",
    "                else:\n",
    "                    label = 'high'\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith('_out.wav'):\n",
    "                    audio_path = os.path.join(folder_path, file)\n",
    "                    audio_files.append(audio_path)\n",
    "                    labels.append(label)\n",
    "                    \n",
    "    return audio_files, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features using VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vggish_features(vggish_model, audio_files):\n",
    "    features = []\n",
    "    for file in audio_files:\n",
    "        examples_batch = preprocess_audio_vggish(file)\n",
    "        embeddings = vggish_model(examples_batch)\n",
    "        features.append(np.mean(embeddings, axis=0))\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(input_shape):\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "#         tf.keras.layers.Dense(128, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(3, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Python\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Python\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Python\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Python\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load VGGish model\n",
    "vggish_model = load_vggish_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Binding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=float32, sparse=None, name=keras_tensor>,) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mvggish_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling1D()(x)\n\u001b[0;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:817\u001b[0m, in \u001b[0;36m_call_attribute\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 817\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\function_type_utils.py:446\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[1;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[0;32m    442\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mbind_with_defaults(\n\u001b[0;32m    443\u001b[0m       args, sanitized_kwargs, default_values\n\u001b[0;32m    444\u001b[0m   )\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 446\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    447\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinding inputs to tf.function failed due to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msanitized_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for signature:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "\u001b[1;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=float32, sparse=None, name=keras_tensor>,) and kwargs: {} for signature: (waveform: TensorSpec(shape=(None,), dtype=tf.float32, name=None))."
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "x = vggish_model(inputs)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_directory = 'EATD-Corpus/train_data'\n",
    "validation_directory = 'EATD-Corpus/validation_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and extract training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vggish_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m train_audio_files, train_labels \u001b[38;5;241m=\u001b[39m load_audio_files(train_directory)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract features for training data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_vggish_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvggish_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_audio_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Encode labels\u001b[39;00m\n\u001b[0;32m      8\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mextract_vggish_features\u001b[1;34m(vggish_model, audio_files)\u001b[0m\n\u001b[0;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m audio_files:\n\u001b[1;32m----> 4\u001b[0m     examples_batch \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_audio_vggish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m vggish_model(examples_batch)\n\u001b[0;32m      6\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mpreprocess_audio_vggish\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_audio_vggish\u001b[39m(audio_path):\n\u001b[1;32m----> 3\u001b[0m     audio_data, sample_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_path, sr\u001b[38;5;241m=\u001b[39m\u001b[43mvggish_params\u001b[49m\u001b[38;5;241m.\u001b[39mSAMPLE_RATE)\n\u001b[0;32m      5\u001b[0m     examples_batch \u001b[38;5;241m=\u001b[39m vggish_input\u001b[38;5;241m.\u001b[39mwaveform_to_examples(audio_data, sample_rate)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m examples_batch\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vggish_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_audio_files, train_labels = load_audio_files(train_directory)\n",
    "\n",
    "# Extract features for training data\n",
    "train_features = extract_vggish_features(vggish_model, train_audio_files)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_labels_encoded = le.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and extract validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validationation data\n",
    "validation_audio_files, validation_labels = load_audio_files(validation_directory)\n",
    "\n",
    "# Extract features for validationation data\n",
    "validation_features = extract_vggish_features(vggish_model, validation_audio_files)\n",
    "\n",
    "# Encode labels\n",
    "validation_labels_encoded = le.transform(validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 20\n",
    "\n",
    "input_shape = train_features.shape[1:]\n",
    "model = build_model(input_shape)\n",
    "model.fit(train_features, train_labels_encoded, \n",
    "          epochs=EPOCH, \n",
    "          batch_size=32, \n",
    "          validation_data=(validation_features, validation_labels_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pred = model.predict(validation_features)\n",
    "validation_pred_labels = np.argmax(validation_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tes metrik evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation metrics\n",
    "print(classification_report(validation_labels_encoded, validation_pred_labels, target_names=le.classes_))\n",
    "print(confusion_matrix(validation_labels_encoded, validation_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
